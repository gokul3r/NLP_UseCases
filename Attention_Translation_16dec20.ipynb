{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "f8-HYI1B2fRS"
      },
      "outputs": [],
      "source": [
        "#Languages: Sentence Pairs http://www.manythings.org/bilingual/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "J4QqyooFNjw1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "i6D3uuZF-kGg"
      },
      "outputs": [],
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BkkW-zshxmhs",
        "outputId": "8a15eb4b-a7cd-4937-8e6b-7316d0128394"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/spa-eng/spa.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "path_to_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YBIpd8hu-tRT"
      },
      "outputs": [],
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEJ8GVtK_Q4u",
        "outputId": "a5106eb0-1560-494b-ddf0-0d19efb5eb23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> hello dubai , i am d speaking hai . <end>\n"
          ]
        }
      ],
      "source": [
        "print(preprocess_sentence(\"hello Dubai, I am D66 speaking# hai.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nCef33MSzE_O",
        "outputId": "16f64124-84ad-4e3f-9046-d980c73a99f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/spa-eng/spa.txt'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "path_to_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7GurUR3jAUVT"
      },
      "outputs": [],
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLOkTqW4AV6t",
        "outputId": "87dedab4-3b8d-4e23-8930-fc9281adbb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> hop in . <end>\n",
            "<start> metete adentro . <end>\n"
          ]
        }
      ],
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[39])\n",
        "print(sp[39])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLOKZjdmA1NX",
        "outputId": "5c3434f6-399f-42e0-f9d6-237ce137489c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[], [], []]\n"
          ]
        }
      ],
      "source": [
        "list1 = [\"hi how are you\", \"hope you doing well\", \"hop inside the car\"]\n",
        "lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "tens = lang_tokenizer.texts_to_sequences(list1)\n",
        "print(tens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9c-E4xHwAqa_"
      },
      "outputs": [],
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kpXqXHLOC7Qk"
      },
      "outputs": [],
      "source": [
        "#Creates input,Target tensors/tuples   &&    input and target language's tokenizers\n",
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "  print(len(inp_lang))\n",
        "  print(len(targ_lang))\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDI_dfY9EHxG",
        "outputId": "96152bd5-1064-469a-92dc-dd5978e282b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n",
            "20000\n",
            "Maximum length of Target: 10\n",
            "Maximum length of Input: 16\n"
          ]
        }
      ],
      "source": [
        "num_examples = 20000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(\"Maximum length of Target:\",max_length_targ)\n",
        "print(\"Maximum length of Input:\", max_length_inp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0QxYa1XEMnV",
        "outputId": "ffe8f864-2568-492c-ac1b-b45b2d5c5416"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "input_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXyV2w9XE4bp",
        "outputId": "9ab94910-2a64-430e-b48f-8d87807531a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000 16000 4000 4000\n"
          ]
        }
      ],
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "AbDcpRr0Jpbi"
      },
      "outputs": [],
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iZP-JYKKQZR",
        "outputId": "f357be30-7c2b-4222-abe0-7635a28efde5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1, 170, 701,   3,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "input_tensor_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojMYDO_hK_IJ",
        "outputId": "6e1ba175-2ea9-491c-9670-e1b037f7402a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "5 ----> ¿\n",
            "31 ----> soy\n",
            "25 ----> una\n",
            "594 ----> mala\n",
            "414 ----> persona\n",
            "4 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "48 ----> am\n",
            "4 ----> i\n",
            "11 ----> a\n",
            "139 ----> bad\n",
            "445 ----> person\n",
            "6 ----> ?\n",
            "2 ----> <end>\n"
          ]
        }
      ],
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[2])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRgKUfvoPXZv",
        "outputId": "ae299f73-dc33-4d61-c103-b880965a81d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7176\n",
            "3727\n",
            "16000\n"
          ]
        }
      ],
      "source": [
        "print(len(inp_lang.word_index))\n",
        "print(len(targ_lang.word_index))\n",
        "print(len(input_tensor_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mErwf3Yfz_z_",
        "outputId": "2d9b75c4-c97a-4987-c511-27a6b8da891c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500.0"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "16000/32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtEyUrxJLnvz",
        "outputId": "a4934fde-7132-4432-db24-1cc9226b5824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 32\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "print(steps_per_epoch)\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUMEsRDZQN8-",
        "outputId": "24d3524c-5a3f-40f6-be3d-3b2e5d3d8d3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 16]), TensorShape([32, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "zUVcqQ3Jcne7"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GafQSV38jfBq",
        "outputId": "7cc63349-c6af-4b75-ca7a-8e880ebc1c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (32, 16, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (32, 1024)\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "22q3ecmFma-K"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # query hidden state shape == (batch_size, hidden size)\n",
        "    # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # values shape == (batch_size, max_len, hidden size)\n",
        "    # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "    query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsokDU5kmc5S",
        "outputId": "7f451962-cfcc-4672-fea5-05230e428b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch size, units) (32, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (32, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "G-QwN7zlml_N"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc =  tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # used for attention\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlWdYQaanBq6",
        "outputId": "49a6bc39-ea90-493a-b112-82c8dcbbdc90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (32, 3728)\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "mIQa8zB1oI66"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "AVcMPFaxoKrU"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "TX9y7KNGoc8A"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - feeding the target as the next input\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # using teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynWtztZ7ouLD",
        "outputId": "34145e99-2f9a-46e8-e250-43a5ed2e501c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 4.5487\n",
            "Epoch 1 Batch 100 Loss 2.2772\n",
            "Epoch 1 Batch 200 Loss 1.9255\n",
            "Epoch 1 Batch 300 Loss 1.6915\n",
            "Epoch 1 Batch 400 Loss 1.7059\n",
            "Epoch 1 Loss 1.9733\n",
            "Time taken for 1 epoch 35.499309062957764 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4645\n",
            "Epoch 2 Batch 100 Loss 1.3254\n",
            "Epoch 2 Batch 200 Loss 1.3929\n",
            "Epoch 2 Batch 300 Loss 1.2806\n",
            "Epoch 2 Batch 400 Loss 1.1469\n",
            "Epoch 2 Loss 1.2811\n",
            "Time taken for 1 epoch 24.71331286430359 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 1.0136\n",
            "Epoch 3 Batch 100 Loss 0.8967\n",
            "Epoch 3 Batch 200 Loss 1.0018\n",
            "Epoch 3 Batch 300 Loss 0.7453\n",
            "Epoch 3 Batch 400 Loss 0.9445\n",
            "Epoch 3 Loss 0.8469\n",
            "Time taken for 1 epoch 24.554094076156616 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.5056\n",
            "Epoch 4 Batch 100 Loss 0.6641\n",
            "Epoch 4 Batch 200 Loss 0.7836\n",
            "Epoch 4 Batch 300 Loss 0.5570\n",
            "Epoch 4 Batch 400 Loss 0.5178\n",
            "Epoch 4 Loss 0.5561\n",
            "Time taken for 1 epoch 24.87343978881836 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.5536\n",
            "Epoch 5 Batch 100 Loss 0.3331\n",
            "Epoch 5 Batch 200 Loss 0.3221\n",
            "Epoch 5 Batch 300 Loss 0.3968\n",
            "Epoch 5 Batch 400 Loss 0.4843\n",
            "Epoch 5 Loss 0.3700\n",
            "Time taken for 1 epoch 24.34378933906555 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.3076\n",
            "Epoch 6 Batch 100 Loss 0.2033\n",
            "Epoch 6 Batch 200 Loss 0.2731\n",
            "Epoch 6 Batch 300 Loss 0.3870\n",
            "Epoch 6 Batch 400 Loss 0.2212\n",
            "Epoch 6 Loss 0.2549\n",
            "Time taken for 1 epoch 24.931753635406494 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1961\n",
            "Epoch 7 Batch 100 Loss 0.2061\n",
            "Epoch 7 Batch 200 Loss 0.1807\n",
            "Epoch 7 Batch 300 Loss 0.1797\n",
            "Epoch 7 Batch 400 Loss 0.1199\n",
            "Epoch 7 Loss 0.1820\n",
            "Time taken for 1 epoch 24.422054529190063 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.1210\n",
            "Epoch 8 Batch 100 Loss 0.1151\n",
            "Epoch 8 Batch 200 Loss 0.1151\n",
            "Epoch 8 Batch 300 Loss 0.1135\n",
            "Epoch 8 Batch 400 Loss 0.1258\n",
            "Epoch 8 Loss 0.1433\n",
            "Time taken for 1 epoch 24.836174726486206 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0840\n",
            "Epoch 9 Batch 100 Loss 0.0758\n",
            "Epoch 9 Batch 200 Loss 0.1303\n",
            "Epoch 9 Batch 300 Loss 0.2197\n",
            "Epoch 9 Batch 400 Loss 0.1049\n",
            "Epoch 9 Loss 0.1139\n",
            "Time taken for 1 epoch 24.434435844421387 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0786\n",
            "Epoch 10 Batch 100 Loss 0.0885\n",
            "Epoch 10 Batch 200 Loss 0.0859\n",
            "Epoch 10 Batch 300 Loss 0.1254\n",
            "Epoch 10 Batch 400 Loss 0.1172\n",
            "Epoch 10 Loss 0.0938\n",
            "Time taken for 1 epoch 24.89706301689148 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ivg6E7nLo8Um"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "0NtNlBciqFvm"
      },
      "outputs": [],
      "source": [
        "# function for plotting the attention weights\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pjTWzAZhqRVW"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKTvpNnnqZAf",
        "outputId": "4b008939-efde-460e-af8e-d7312d03c2a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fb521d26690>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "bXYj43haqoKU",
        "outputId": "76644ec3-2528-46ee-a5d2-b904d15addc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold . <end> \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(translate(u'hace mucho frio aqui.'))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Attention-Translation-16dec20.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}